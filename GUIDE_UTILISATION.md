# Guide d'Utilisation - IAction

## üöÄ D√©marrage Rapide

### 1. V√©rification de la Configuration
```bash
# Test complet (plus lent)
python test_config.py


### 2. D√©marrage de l'Application
```bash
# M√©thode 1: Script automatique
start.bat

# M√©thode 2: Commande directe
python app.py
```

### 3. Acc√®s √† l'Interface
Ouvrez votre navigateur sur : `http://localhost:5000`

## üìã Pr√©requis

### Services Requis
1. **OpenAI API** ou **LM Studio** pour l'analyse d'images
2. **Broker MQTT** (optionnel pour Home Assistant)

### Options pour l'API Vision

#### Option 1: OpenAI API (recommand√©)
```bash
# Obtenez une cl√© API sur https://platform.openai.com
# Puis configurez-la dans le fichier .env
```

#### Option 2: LM Studio (local)
```bash
# T√©l√©chargez depuis https://lmstudio.ai
# Installez un mod√®le vision compatible (comme qwen2.5-vl-7b)
# D√©marrez le serveur API dans LM Studio sur le port 11434
```

#### Option 3: LM Studio avec Ollama (configuration alternative)
```bash
# Vous pouvez utiliser LM Studio pour acc√©der aux mod√®les d'Ollama
# 1. Installez Ollama depuis https://ollama.ai
# 2. Installez un mod√®le vision : ollama pull qwen2.5vl:7b
# 3. D√©marrez Ollama
# 4. Configurez AI_API_MODE=lmstudio dans .env
# 5. Assurez-vous que LMSTUDIO_URL pointe vers http://127.0.0.1:11434/v1
```

### Installation Mosquitto (MQTT)
```bash
# Windows: T√©l√©chargez depuis https://mosquitto.org/download/
# Ou utilisez Docker:
docker run -it -p 1883:1883 eclipse-mosquitto
```

## ‚öôÔ∏è Configuration

### Fichier .env
Modifiez le fichier `.env` avec vos param√®tres :

```env
# Configuration AI (OpenAI ou LM Studio)
AI_API_MODE=lmstudio  # Options: 'openai' ou 'lmstudio'
AI_TIMEOUT=60

# Configuration OpenAI
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4-vision-preview

# Configuration LM Studio (compatible avec l'API d'Ollama sur le port 11434)
LMSTUDIO_URL=http://127.0.0.1:11434/v1
LMSTUDIO_MODEL=qwen/qwen2.5-vl-7b
# Configuration Ollama (obsol√®te)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=qwen2.5vl:7b
# MQTT (pour Home Assistant)
MQTT_BROKER=192.168.1.100
MQTT_PORT=1883
MQTT_USERNAME=homeassistant
MQTT_PASSWORD=votre_mot_de_passe

# Home Assistant
HA_DEVICE_NAME=IAction Camera AI
HA_DEVICE_ID=iaction_camera_ai
```

## üéØ Utilisation

### üíª Configuration de l'API Vision

### Utilisation de LM Studio avec Ollama (Configuration actuelle)

La configuration actuelle utilise LM Studio pour acc√©der aux mod√®les d'Ollama via l'API compatible OpenAI. Voici comment cela fonctionne :

1. **Installation d'Ollama** :
   ```bash
   # T√©l√©chargez depuis https://ollama.ai
   # Puis installez le mod√®le vision Qwen
   ollama pull qwen2.5vl:7b
   ```

2. **Configuration du fichier .env** :
   ```env
   AI_API_MODE=lmstudio
   LMSTUDIO_URL=http://127.0.0.1:11434/v1
   LMSTUDIO_MODEL=qwen/qwen2.5-vl-7b
   ```

3. **Fonctionnement** :
   - L'application se connecte √† l'API d'Ollama sur le port 11434
   - Elle utilise le format de requ√™te compatible avec l'API OpenAI
   - Les images sont envoy√©es au mod√®le Qwen pour analyse
   - Les r√©sultats sont trait√©s et publi√©s via MQTT

### Utilisation de l'API OpenAI (Alternative)

Pour utiliser l'API OpenAI officielle :

1. **Obtenir une cl√© API** sur https://platform.openai.com

2. **Modifier le fichier .env** :
   ```env
   AI_API_MODE=openai
   OPENAI_API_KEY=sk-votre-cl√©-api-ici
   OPENAI_MODEL=gpt-4-vision-preview
   ```

### Configuration d'une Cam√©ra

#### Cam√©ra USB
1. Connectez votre cam√©ra USB
2. Dans l'interface, s√©lectionnez "Cam√©ra USB X"
3. Cliquez "D√©marrer la capture"

#### Cam√©ra IP (RTSP)
1. S√©lectionnez "Cam√©ra RTSP (URL personnalis√©e)"
2. Saisissez l'URL : `rtsp://user:pass@192.168.1.100:554/stream1`
3. Cliquez "D√©marrer la capture"

### D√©tections Personnalis√©es

#### Ajouter une D√©tection
1. Cliquez sur "Ajouter" dans la section "D√©tections Personnalis√©es"
2. Saisissez un nom descriptif
3. D√©crivez pr√©cis√©ment ce que l'IA doit d√©tecter

#### Exemples de D√©tections
- **Nom** : Personne avec t√©l√©phone
- **Phrase** : une personne qui tient un t√©l√©phone portable

- **Nom** : V√©hicule en mouvement
- **Phrase** : une voiture ou un camion qui roule

- **Nom** : Animal domestique
- **Phrase** : un chien ou un chat

### Capteurs Automatiques

L'application g√©n√®re automatiquement :
- **Compteur de personnes** : Nombre de personnes visibles

## üè† Int√©gration Home Assistant

### Configuration MQTT
1. Activez MQTT dans Home Assistant
2. Configurez le broker dans `.env`
3. Les capteurs appara√Ætront automatiquement

### Capteurs Disponibles
- `sensor.iaction_camera_ai_people_count`
- `sensor.iaction_camera_ai_scene_description`
- `binary_sensor.iaction_camera_ai_detection_[nom]`

### Automatisations Exemple
```yaml
# Notification si plus de 3 personnes
automation:
  - alias: "Trop de monde"
    trigger:
      platform: numeric_state
      entity_id: sensor.iaction_camera_ai_people_count
      above: 3
    action:
      service: notify.mobile_app
      data:
        message: "Plus de 3 personnes d√©tect√©es !"

# Action sur d√©tection personnalis√©e
  - alias: "D√©tection personnalis√©e"
    trigger:
      platform: state
      entity_id: binary_sensor.iaction_camera_ai_detection_xxxxx
      to: 'on'
    action:
      service: light.turn_on
      entity_id: light.salon
```

## üîß D√©pannage

### Probl√®mes Courants

#### "Aucune cam√©ra d√©tect√©e"
- V√©rifiez que la cam√©ra est connect√©e
- Testez avec une autre application (VLC, etc.)
- Red√©marrez l'application


#### "Erreur Ollama"
```bash
# V√©rifiez qu'Ollama fonctionne
ollama serve

# Testez la connexion
curl http://localhost:11434/api/tags

# Installez un mod√®le si n√©cessaire
ollama pull qwen2.5vl:7b
```

#### "Erreur MQTT"
- V√©rifiez que le broker MQTT est d√©marr√©
- Testez la connexion :
```bash
mosquitto_pub -h localhost -t test -m "hello"
mosquitto_sub -h localhost -t test
```

#### "Analyse IA lente"
- R√©duisez la r√©solution de la cam√©ra
- V√©rifiez les ressources syst√®me (CPU/RAM)

### Logs et Debug
- Les logs s'affichent dans la console Python
- L'interface web montre l'activit√© en temps r√©el
- Utilisez `test_config.py` pour diagnostiquer

## üìä Performance

### Ressources Recommand√©es
- **CPU** : 4 c≈ìurs minimum
- **RAM** : 8 GB minimum (16 GB recommand√©)
- **GPU** : Optionnel mais am√©liore les performances

### Optimisation
- Utilisez des mod√®les Ollama optimis√©s
- Limitez le nombre de d√©tections simultan√©es
- Ajustez la r√©solution vid√©o selon vos besoins

## üîí S√©curit√©

### Bonnes Pratiques
- Changez les mots de passe par d√©faut
- Utilisez HTTPS en production
- Limitez l'acc√®s r√©seau si n√©cessaire
- Sauvegardez r√©guli√®rement vos configurations

### Donn√©es Priv√©es
- Les images sont analys√©es localement
- Aucune donn√©e n'est envoy√©e vers des services externes
- Ollama fonctionne enti√®rement en local

## üìû Support

### Fichiers de Log
- Console Python pour les erreurs syst√®me
- Interface web pour l'activit√© utilisateur
- Logs MQTT dans Home Assistant

### Informations Utiles
- Version Python : `python --version`
- √âtat des services : `python test_config.py`
- Mode API actuel : v√©rifiez `AI_API_MODE` dans le fichier `.env`

---

**IAction** - Analyse Vid√©o IA pour Home Assistant
Version 1.0 - D√©velopp√© avec ‚ù§Ô∏è
